{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpot2\n",
    "import sklearn.metrics\n",
    "import sklearn\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# display stuff\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# variables used throughout\n",
    "task_id_lists = [167104, 167184, 167168, 167161, 167185, 189905, 167152, 167181, 189906, 189862, 167149, 189865, 167190, 189861, 189872, 168794, 189871, 168796, 168797, 75097, 126026, 189909, 126029, 126025, 75105, 168793, 189874, 167201, 189908, 189860, 168792, 167083, 167200, 168798, 189873, 189866, 75127, 75193]\n",
    "data_dir = '../../Results_Prelim/'\n",
    "replicates = 30\n",
    "exp_dirs = ['Base/', '10/Lexicase/','30/Lexicase/','50/Lexicase/']\n",
    "seeds = [0,1200,2400,3200]\n",
    "proportions = [0.0, 0.1, 0.3, 0.5]\n",
    "data_pkl = 'data.pkl'\n",
    "scores_pkl = 'scores.pkl'\n",
    "failed_pkl = 'failed.pkl'\n",
    "scores_key = ['train_auroc','train_accuracy','train_balanced_accuracy','train_logloss','auroc','accuracy','balanced_accuracy','logloss','taskid','selection','seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data holders\n",
    "SCORES_DF = []\n",
    "OVER_TIME_DF = []\n",
    "\n",
    "for cur_dir,seed, proportion in zip(exp_dirs,seeds, proportions):\n",
    "\n",
    "    dir = data_dir + cur_dir\n",
    "\n",
    "    if proportion == 0.0:\n",
    "        acro = 'base'\n",
    "    elif proportion == 0.1:\n",
    "        acro = 'lex-10%'\n",
    "    elif proportion == 0.3:\n",
    "        acro = 'lex-30%'\n",
    "    elif proportion == 0.5:\n",
    "        acro = 'lex-50%'\n",
    "\n",
    "    print('dir:',dir)\n",
    "    print('acro:',acro)\n",
    "\n",
    "    for subdir, dirs, files in os.walk(dir):\n",
    "        # skip root dir\n",
    "        if subdir == dir:\n",
    "            continue\n",
    "        # skip failed (will fix on the go)\n",
    "        if os.path.exists(subdir + failed_pkl):\n",
    "            continue\n",
    "\n",
    "        # scores dictionary data (swap wit upper block if we care about seed, then pass seed down)\n",
    "        scores_dict = pkl.load(open(subdir + scores_pkl,'rb'))\n",
    "        scores_df = pd.DataFrame([scores_dict],  columns=scores_dict.keys())[scores_key]\n",
    "        scores_df['proportion'] = float(int(proportion[:-1]) / 100.0)\n",
    "        scores_df['acro'] = acro\n",
    "        SCORES_DF.append(scores_df)\n",
    "\n",
    "        # over time data\n",
    "        data_df = pkl.load(open(subdir + data_pkl,'rb'))\n",
    "        data_df['taskid'] = scores_dict['taskid']\n",
    "        data_df['proportion'] = proportion\n",
    "        data_df['acro'] = acro\n",
    "        OVER_TIME_DF.append(data_df)\n",
    "\n",
    "\n",
    "final_data = pd.concat(OVER_TIME_DF)\n",
    "final_scores = pd.concat(SCORES_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(path_or_buf='ot_data.csv', index=False)\n",
    "final_scores.to_csv(path_or_buf='scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpot2-env-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
