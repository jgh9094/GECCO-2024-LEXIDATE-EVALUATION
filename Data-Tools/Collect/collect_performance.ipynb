{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpot2\n",
    "import sklearn.metrics\n",
    "import sklearn\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# display stuff\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# variables used throughout\n",
    "task_id_lists = [167104, 167184, 167168, 167161, 167185, 189905, 167152, 167181, 189906, 189862, 167149, 189865, 167190, 189861, 189872, 168794, 189871, 168796, 168797, 75097, 126026, 189909, 126029, 126025, 75105, 168793, 189874, 167201, 189908, 189860, 168792, 167083, 167200, 168798, 189873, 189866, 75127, 75193]\n",
    "data_dir = '../../Results/'\n",
    "replicates = 30\n",
    "exp_dirs = ['Base/', 'Lexi-10/','Lexi-30/','Lex-50/']\n",
    "seeds = [5000,5300,5600,5900]\n",
    "proportions = [0.0, 0.1, 0.3, 0.5]\n",
    "data_pkl = '/data.pkl'\n",
    "scores_pkl = '/scores.pkl'\n",
    "failed_pkl = '/failed.pkl'\n",
    "evaluated_pkl = '/evaluated_individuals.pkl'\n",
    "fitted_pkl = '/fitted_pipeline.pkl'\n",
    "\n",
    "scores_key = ['train_auroc','train_accuracy','train_balanced_accuracy','train_logloss','auroc','accuracy','balanced_accuracy','logloss','taskid','selection','seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data holders\n",
    "SCORES_DF = []\n",
    "OVER_TIME_DF = []\n",
    "\n",
    "for cur_dir,seed, proportion in zip(exp_dirs,seeds, proportions):\n",
    "\n",
    "    dir = data_dir + cur_dir\n",
    "\n",
    "    if proportion == 0.0:\n",
    "        acro = 'base'\n",
    "    elif proportion == 0.1:\n",
    "        acro = '90/10'\n",
    "    elif proportion == 0.3:\n",
    "        acro = '70/30'\n",
    "    elif proportion == 0.5:\n",
    "        acro = '50/50'\n",
    "\n",
    "    print('dir:',dir)\n",
    "    print('acro:',acro)\n",
    "\n",
    "    for subdir, dirs, files in os.walk(dir):\n",
    "        # skip root dir\n",
    "        if subdir == dir:\n",
    "            continue\n",
    "        # skip failed (will fix on the go)\n",
    "        if os.path.exists(subdir + failed_pkl):\n",
    "            continue\n",
    "\n",
    "        # folder is empty\n",
    "        if os.path.exists(subdir + failed_pkl) is False and os.path.exists(subdir + data_pkl) is False and \\\n",
    "            os.path.exists(subdir + evaluated_pkl) is False and os.path.exists(subdir + scores_pkl) is False and \\\n",
    "            os.path.exists(subdir + fitted_pkl) is False:\n",
    "            continue\n",
    "\n",
    "        # scores dictionary data (swap wit upper block if we care about seed, then pass seed down)\n",
    "        scores_dict = pkl.load(open(subdir + scores_pkl,'rb'))\n",
    "        scores_df = pd.DataFrame([scores_dict],  columns=scores_dict.keys())[scores_key]\n",
    "        scores_df['proportion'] = proportion\n",
    "        scores_df['acro'] = acro\n",
    "        SCORES_DF.append(scores_df)\n",
    "\n",
    "        # over time data\n",
    "        data_df = pkl.load(open(subdir + data_pkl,'rb'))\n",
    "        data_df['taskid'] = scores_dict['taskid']\n",
    "        data_df['proportion'] = proportion\n",
    "        data_df['acro'] = acro\n",
    "        data_df['seed'] = subdir.split('/')[-1].split('-')[0]\n",
    "        OVER_TIME_DF.append(data_df)\n",
    "\n",
    "\n",
    "final_data = pd.concat(OVER_TIME_DF)\n",
    "final_scores = pd.concat(SCORES_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(path_or_buf='ot_data.csv', index=False)\n",
    "final_scores.to_csv(path_or_buf='scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
